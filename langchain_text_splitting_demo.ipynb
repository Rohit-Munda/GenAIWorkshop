{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit-Munda/GenAIWorkshop/blob/main/langchain_text_splitting_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ec6623d",
      "metadata": {
        "id": "7ec6623d"
      },
      "source": [
        "# ğŸ§  LangChain Workshop: Document Loading & Text Splitting\n",
        "Welcome! In this hands-on session, we will:\n",
        "- Load a document using LangChain\n",
        "- Explore different text splitting techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9075c176",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9075c176",
        "outputId": "36be2275-01c4-4275-bf1c-0b3490b319d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.1/1.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain_community tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "990671b6",
      "metadata": {
        "id": "990671b6"
      },
      "source": [
        "## ğŸ“„ Step 1: Create and Load a Sample Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5fb9ddae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fb9ddae",
        "outputId": "32834dd1-11e4-4532-d4de-19df5f3e3528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded document:\n",
            "Artificial Intelligence (AI) is transforming industries across the globe. From healthcare to finance, AI applications are driving innovation. Large Language Models (LLMs) are at the core of this revolution, enabling machines to understand and generate human-like language. In this session, we explore how to prepare documents for LLMs using LangChain.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Create a sample text file\n",
        "sample_text = (\n",
        "    \"Artificial Intelligence (AI) is transforming industries across the globe. \"\n",
        "    \"From healthcare to finance, AI applications are driving innovation. \"\n",
        "    \"Large Language Models (LLMs) are at the core of this revolution, enabling machines to understand and generate human-like language. \"\n",
        "    \"In this session, we explore how to prepare documents for LLMs using LangChain.\"\n",
        ")\n",
        "\n",
        "with open(\"sample_doc.txt\", \"w\") as f:\n",
        "    f.write(sample_text)\n",
        "\n",
        "# Load the document\n",
        "loader = TextLoader(\"sample_doc.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "print(\"Loaded document:\")\n",
        "print(documents[0].page_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "633f2e75",
      "metadata": {
        "id": "633f2e75"
      },
      "source": [
        "## âœ‚ï¸ Step 2: Basic Text Splitting with `CharacterTextSplitter`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c6cf27b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6cf27b0",
        "outputId": "b1efeea8-1c08-4de6-b59f-d3e9348b5aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 12\n",
            "Chunk 1: Artificial Intelligence (AI) is\n",
            "Chunk 2: (AI) is transforming industries across\n",
            "Chunk 3: across the globe. From healthcare to\n",
            "Chunk 4: to finance, AI applications are driving\n",
            "Chunk 5: driving innovation. Large Language\n",
            "Chunk 6: Language Models (LLMs) are at the core\n",
            "Chunk 7: the core of this revolution, enabling\n",
            "Chunk 8: enabling machines to understand and\n",
            "Chunk 9: and generate human-like language. In\n",
            "Chunk 10: In this session, we explore how to\n",
            "Chunk 11: how to prepare documents for LLMs using\n",
            "Chunk 12: LLMs using LangChain.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "splitter = CharacterTextSplitter(separator=\" \", chunk_size=40, chunk_overlap=10)\n",
        "basic_chunks = splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Number of chunks: {len(basic_chunks)}\")\n",
        "for i, chunk in enumerate(basic_chunks):\n",
        "    print(f\"Chunk {i+1}: {chunk.page_content}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90151ad4",
      "metadata": {
        "id": "90151ad4"
      },
      "source": [
        "## ğŸ” Step 3: Recursive Splitting with `RecursiveCharacterTextSplitter`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bf75e3e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf75e3e4",
        "outputId": "6d3e1a74-abf6-42da-8599-567e9205b867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 11\n",
            "Chunk 1: Artificial Intelligence (AI) is transforming\n",
            "Chunk 2: transforming industries across the globe. From\n",
            "Chunk 3: globe. From healthcare to finance, AI\n",
            "Chunk 4: to finance, AI applications are driving\n",
            "Chunk 5: are driving innovation. Large Language Models\n",
            "Chunk 6: Models (LLMs) are at the core of this revolution,\n",
            "Chunk 7: revolution, enabling machines to understand and\n",
            "Chunk 8: understand and generate human-like language. In\n",
            "Chunk 9: language. In this session, we explore how to\n",
            "Chunk 10: explore how to prepare documents for LLMs using\n",
            "Chunk 11: for LLMs using LangChain.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "recursive_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=15)\n",
        "recursive_chunks = recursive_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Number of chunks: {len(recursive_chunks)}\")\n",
        "for i, chunk in enumerate(recursive_chunks):\n",
        "    print(f\"Chunk {i+1}: {chunk.page_content}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9520610c",
      "metadata": {
        "id": "9520610c"
      },
      "source": [
        "## ğŸ§® Step 4: Token-based Splitting with `TokenTextSplitter`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d6193721",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6193721",
        "outputId": "2aa3e48f-5fbf-4626-ee6a-6d043aae6d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 5\n",
            "Chunk 1: Artificial Intelligence (AI) is transforming industries across the globe. From healthcare to finance, AI applications\n",
            "Chunk 2:  to finance, AI applications are driving innovation. Large Language Models (LLMs) are at the core\n",
            "Chunk 3: ) are at the core of this revolution, enabling machines to understand and generate human-like language.\n",
            "Chunk 4:  human-like language. In this session, we explore how to prepare documents for LLMs using Lang\n",
            "Chunk 5:  for LLMs using LangChain.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "\n",
        "token_splitter = TokenTextSplitter(chunk_size=20, chunk_overlap=5)\n",
        "token_chunks = token_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Number of chunks: {len(token_chunks)}\")\n",
        "for i, chunk in enumerate(token_chunks):\n",
        "    print(f\"Chunk {i+1}: {chunk.page_content}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "086c95e6",
      "metadata": {
        "id": "086c95e6"
      },
      "source": [
        "\n",
        "## ğŸ“Š Comparison of Text Splitting Strategies\n",
        "\n",
        "| Splitter Type                   | Description                                                                 | Use Case                                                                 |\n",
        "|---------------------------------|-----------------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
        "| `CharacterTextSplitter`        | Splits text using a simple character-based separator like space or newline | Simple, fast, good for small documents with regular structure            |\n",
        "| `RecursiveCharacterTextSplitter`| Tries different levels of granularity (e.g., paragraphs, sentences)        | More intelligent splitting, avoids cutting off in the middle of sentences|\n",
        "| `TokenTextSplitter`            | Splits based on token count (e.g., for LLM input limits)                   | Ideal for managing input size limits in transformer models               |\n",
        "\n",
        "Each strategy has its advantages depending on the structure and size of your documents. Use `RecursiveCharacterTextSplitter` when preserving sentence meaning is important. Use `TokenTextSplitter` when working with models that have strict token limits.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddb35ef2",
      "metadata": {
        "id": "ddb35ef2"
      },
      "source": [
        "## âœ… Summary\n",
        "In this notebook, you've learned how to:\n",
        "- Load documents using LangChain\n",
        "- Apply different text splitting techniques:\n",
        "  - Character-based splitting\n",
        "  - Recursive splitting\n",
        "  - Token-based splitting\n",
        "\n",
        "These techniques are essential for preparing data for large language models (LLMs)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}