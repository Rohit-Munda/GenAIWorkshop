{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJ5wODqec5reBjDnmMuueo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit-Munda/GenAIWorkshop/blob/main/PromptEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CcAJYykDIl2W"
      },
      "outputs": [],
      "source": [
        "#Import necessary packages\n",
        "from huggingface_hub import InferenceClient\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔑 Enter your Hugging Face token here (use `input()` or `getpass`)\n",
        "HF_TOKEN = getpass(\"Enter your Hugging Face API token: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y5M6uS3I28d",
        "outputId": "5c21af04-39fa-4f3c-8401-04833b4c1070"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face API token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize client\n",
        "client = InferenceClient(\n",
        "    model=\"distilbert/distilgpt2\",  # You can change this model\n",
        "    token=HF_TOKEN\n",
        ")"
      ],
      "metadata": {
        "id": "MVuDEQyTJYks"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(prompt, max_tokens=200, temperature=0.7):\n",
        "    response = client.text_generation(\n",
        "        prompt,\n",
        "        max_new_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        do_sample=True\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "-WnrOnmVJcae"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain what a Large Language Model is in simple terms.\"\n",
        "print(chat(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgssvoK5JjyD",
        "outputId": "e8f472da-fb27-444d-9603-7b8fe724e97b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain what a Large Language Model is in simple terms.\n",
            "\n",
            "\n",
            "It’s a bit of a \"changaroo class\" to use the language\n",
            "A lot of the language development machinery is handled by a language where the language is just a small subset of the language or language. The language is built on a architecture or compilation program which is known as a compiler and compiler.\n",
            "The compiler is usually just a small subset of the language.\n",
            "The compiler is usually just a tiny subset of the language or language. The compiler is usually just a small subset of the language or language. The system is very simple.\n",
            "The compiler is usually just a small subset of the language or language. The system is very simple.\n",
            "The system is very simple.\n",
            "The compiler is usually just a small subset of the language or language. The system is very simple. The system is very simple.\n",
            "The system is very simple. The system is very simple. The system is very simple.\n",
            "The system is very simple. The system is very\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"Explain what a Large Language Model is like I'm 5.\"\n",
        "prompt2 = \"Explain what a Large Language Model is to a software engineer.\""
      ],
      "metadata": {
        "id": "Ze7kfK0EMDo5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"👶 Child-friendly explanation:\\n\", chat(prompt1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU0J-pGVMMkR",
        "outputId": "cd215440-ea72-4533-a839-c7119ffaed88"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "👶 Child-friendly explanation:\n",
            " Explain what a Large Language Model is like I'm 5.0. The Open Language Model is written in a language that is not that big. So, I'm using all the problems that I have as the design. I'm not trying to just write a language and it's just trying to make it better. I'm trying to make the language better. I'm trying to make the language better.\n",
            "\n",
            "\n",
            "I'm just trying to make it better. I'm just trying to make the language better. I'm just trying to make the language better. I'm just trying to make the language better. I'm just trying to make the language better.\n",
            "I love to use the language. I love to use the language. I love to use the language. I love to use the language. I love to use the language.\n",
            "So, all that's happening is the problems I see. This is how I write the language.\n",
            "Here are the problems I see. This is how I write the language.\n",
            "I'm not saying that\n"
          ]
        }
      ]
    }
  ]
}