{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit-Munda/GenAIWorkshop/blob/main/Workshop-1/Day-3/DocumentRetrievalQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L9w12IIoH_S"
      },
      "source": [
        "## 🛠 1. Install and load required python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcJofg3MoKX5",
        "outputId": "bb51ff90-8eab-4472-be77-282f7f99f6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q faiss-cpu pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4YgVWp3ogiS"
      },
      "outputs": [],
      "source": [
        "#Import necessary packages\n",
        "import pdfplumber\n",
        "import os\n",
        "import textwrap\n",
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from google.colab import files\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkci2i5UpGwP"
      },
      "source": [
        "## 📂 Step 2. Upload PDF or TXT Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "-iFca8EBpI6Y",
        "outputId": "1a87ec8e-98bf-46ea-9310-4644145b9910"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f62efb4-e244-4245-abb2-76977363fc7b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f62efb4-e244-4245-abb2-76977363fc7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving generative_ai_extended.pdf to generative_ai_extended.pdf\n"
          ]
        }
      ],
      "source": [
        "uploaded_files = files.upload()  # Upload one or more .pdf or .txt files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpIfHCApSS9"
      },
      "source": [
        "## 📄 Step 3. Extract Text from PDFs or Text Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxpUVWibpT-w"
      },
      "outputs": [],
      "source": [
        "def extract_text(file):\n",
        "    if file.endswith('.pdf'):\n",
        "        text = ''\n",
        "        with pdfplumber.open(file) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() + '\\n'\n",
        "        return text\n",
        "    elif file.endswith('.txt'):\n",
        "        with open(file, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQNutcTApfYj",
        "outputId": "09e7bc1b-5533-4127-f267-200013f86e8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        }
      ],
      "source": [
        "# Collect all document texts\n",
        "corpus = []\n",
        "\n",
        "for fname in uploaded_files:\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(uploaded_files[fname])\n",
        "    text = extract_text(fname)\n",
        "    corpus.append(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fsgjg2BpnYx"
      },
      "source": [
        "## ✂️ Step 4. Split Text into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N35y1IECpmAN"
      },
      "outputs": [],
      "source": [
        "def split_into_chunks(text, max_length=300):\n",
        "    return textwrap.wrap(text, width=max_length, break_long_words=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1dpKkJsptS-"
      },
      "outputs": [],
      "source": [
        "# Flatten all chunks from all documents\n",
        "all_chunks = []\n",
        "for doc_text in corpus:\n",
        "    all_chunks.extend(split_into_chunks(doc_text, max_length=300))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvN4AmaCp5_A",
        "outputId": "5e3a527f-7b29-426c-cc05-ebb3a592f31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Total Chunks: 12\n"
          ]
        }
      ],
      "source": [
        "print(f\"✅ Total Chunks: {len(all_chunks)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-f2cAzSp95v"
      },
      "source": [
        "## 🔡 Step 5. Generate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6ghFxONp8qu"
      },
      "outputs": [],
      "source": [
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "chunk_embeddings = embedder.encode(all_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjHaO-6DqIww"
      },
      "source": [
        "## 📦 Step 6. Store in FAISS Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5Z9zpUNqHEL"
      },
      "outputs": [],
      "source": [
        "embedding_dim = chunk_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "index.add(np.array(chunk_embeddings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnyHsO8mqifW"
      },
      "source": [
        "## 🧠 Step 7. RAG Function: Retrieve + Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09o3efkkqjZ2"
      },
      "outputs": [],
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cICZe_BUqpO9"
      },
      "outputs": [],
      "source": [
        "def rag_answer(question, top_k=3):\n",
        "    question_embedding = embedder.encode([question])\n",
        "    distances, indices = index.search(np.array(question_embedding), top_k)\n",
        "    retrieved_chunks = [all_chunks[i] for i in indices[0]]\n",
        "\n",
        "    context = \" \".join(retrieved_chunks)\n",
        "\n",
        "    result = qa_pipeline(question=question, context=context)\n",
        "\n",
        "    print(f\"📌 Question: {question}\")\n",
        "    print(f\"\\n📚 Retrieved Context:\\n{context[:1000]}...\")  # Truncated for display\n",
        "    print(f\"\\n🧠 Answer: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bv-UFqXqwV5",
        "outputId": "76fb7f33-f58c-451e-b3be-67862016a69a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📌 Question: What is the main topic of the document?\n",
            "\n",
            "📚 Retrieved Context:\n",
            "where two networks competeone generates data, and the other evaluates it. Each technique has its own strengths and application areas. 3. Applications of Generative AI Text Generation: Language models like GPT-3 and ChatGPT can generate essays, news articles, conversations, and summaries. Image and inspire creativity. It can democratize access to tools and information by enabling non-experts to generate high-quality content with minimal input. 5. Risks and Challenges Despite its promise, Generative AI also poses risks: - Misinformation: AI-generated fake news and deepfakes can mislead the artificial intelligence, with transformative potential across nearly every industry. As with any powerful technology, its development must be approached with both excitement and responsibility....\n",
            "\n",
            "🧠 Answer: Generative AI Text Generation\n"
          ]
        }
      ],
      "source": [
        "rag_answer(\"What is the main topic of the document?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTE2qA8nq9Xj",
        "outputId": "fb3472cf-e2f3-4611-882f-cb9aac65aa3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📌 Question: As per the document, what are the models used for image generation?\n",
            "\n",
            "📚 Retrieved Context:\n",
            "Generation: Models like DALLE and Stable Diffusion can create original images from text prompts, offering applications in design, art, and media. Music and Audio: AI can compose music in various genres, synthesize voices, and even create new sounds. Code Generation: Tools like GitHub Copilot use various techniques such as: - Transformer Architectures: Models like GPT use attention mechanisms to process and generate sequences of data. - Autoencoders: These compress and reconstruct input data and can be used to generate new data points. - GANs (Generative Adversarial Networks): A framework original data distribution. One of the most well-known classes of generative models are transformer-based language models like OpenAI's GPT series. These models are pre-trained on large text corpora and then fine-tuned for specific tasks. 2. How Do Generative Models Work? Generative models use...\n",
            "\n",
            "🧠 Answer: DALLE and Stable Diffusion\n"
          ]
        }
      ],
      "source": [
        "rag_answer(\"As per the document, what are the models used for image generation?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipP3X1F7rP0-"
      },
      "source": [
        "## ✅ What You Learned\n",
        "\n",
        "- How to build a simple RAG system:\n",
        "  - Load documents (PDFs/TXT)\n",
        "  - Break them into chunks\n",
        "  - Embed and store in a vector database (FAISS)\n",
        "  - Retrieve relevant chunks for a user query\n",
        "  - Use a QA model to generate an answer based on the retrieved content"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzyfqkq6Oqa+F3MtopG/Oc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}